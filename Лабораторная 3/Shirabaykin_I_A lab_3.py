# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OmNRzXAh7B7pc83VWwL2aOgbobT_575N

Импорт необходимых библиотек:
"""

from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical

"""Загружаем данные:"""

(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

"""Изображения имеют размер 28x28 и, следовательно, является
двухмерными. Поскольку наш персептрон способен считывать только
одномерные данные, преобразуем их
"""

x_train = x_train.reshape(x_train.shape[0], -1) / 255.0
x_test = x_test.reshape(x_test.shape[0], -1) / 255.0
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

"""Опишем архитектуру сети:"""

model = Sequential()
model.add(Dense(10, input_dim=784, activation='relu'))
model.add(Dense(10, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam',
metrics=['accuracy'])

"""Начнем обучение:

"""

model.fit(x_train, y_train, epochs=10, validation_split=0.1)

"""Проанализируйте результат на проверочных и тестовых данных.

"""

test_acc = model.evaluate(x_test, y_test)
print(test_acc)

"""Результаты, полученные при оценке модели на тестовых данных, включают два основных показателя:

Loss (функция потерь): 0.4316307008266449
Accuracy (точность): 0.8483 или 84.83%
Анализ результатов
Точность (Accuracy)
Точность модели на тестовом наборе данных составляет 84.83%. Это означает, что модель правильно классифицирует около 85% изображений из тестового набора. Для задачи классификации одежды, которая включает 10 различных классов, такой уровень точности можно считать достаточно хорошим, особенно учитывая простоту модели (только два полносвязных слоя).

**Функция потерь (Loss)**
Значение функции потерь на тестовом наборе данных равно примерно 0.43. Функция потерь категориальной кросс-энтропии измеряет разницу между предсказанными вероятностями и истинными метками классов. Меньшее значение функции потерь указывает на лучшее соответствие модели данным. Значение 0.43 может указывать на то, что модель всё ещё испытывает некоторые трудности в точной классификации всех изображений, но в целом она справляется с задачей.

Опишем архитектуру сети 2:
"""

model2 = Sequential()
model2.add(Dense( 50, input_dim=784, activation='relu'))
model2.add(Dense(10, activation='softmax'))
model2.compile(loss='categorical_crossentropy', optimizer='adam',
metrics=['accuracy'])
model2.fit(x_train, y_train, epochs=10, validation_split=0.1)

test_acc = model2.evaluate(x_test, y_test)
print(test_acc)

"""Проанализируйте результат на проверочных и тестовых данных.

Результаты оценки второй модели на тестовых данных включают два основных показателя:

Loss (функция потерь): 0.3635515570640564
Accuracy (точность): 0.8715 или 87.15%
Анализ результатов
Точность (Accuracy)
Точность модели на тестовом наборе данных составляет 87.15%. Это означает, что модель правильно классифицирует около 87% изображений из тестового набора. По сравнению с первой моделью, это значительное улучшение. Такой уровень точности является высоким для задачи классификации одежды с 10 классами.

**Функция потерь (Loss)**
Значение функции потерь на тестовом наборе данных равно примерно 0.36. Это значение ниже, чем у первой модели, что указывает на лучшее соответствие модели данным. Меньшее значение функции потерь означает, что предсказания модели более близки к истинным меткам классов.

**Сравнение с первой моделью**
Вторая модель показывает улучшение по сравнению с первой моделью как по точности, так и по функции потерь. Увеличение количества нейронов в первом полносвязном слое с 10 до 50 позволило модели лучше обучаться на данных и улучшить результаты.

Опишем архитектуру сети 3:
"""

model3 = Sequential()
model3.add(Dense(50, input_dim=784, activation='relu'))
model3.add(Dense(50, activation='relu'))
model3.add(Dense(10, activation='softmax'))
model3.compile(loss='categorical_crossentropy', optimizer='adam',
metrics=['accuracy'])
model3.fit(x_train, y_train, epochs=10, validation_split=0.1)

"""Проанализируйте результат на проверочных и тестовых данных."""

test_acc = model3.evaluate(x_test, y_test)
print(test_acc)

"""Результаты оценки третьей модели на тестовых данных включают два основных показателя:

Loss (функция потерь): 0.3670
Accuracy (точность): 0.8749 или 87.49%
Анализ результатов
Точность (Accuracy)
Точность модели на тестовом наборе данных составляет 87.49%. Это означает, что модель правильно классифицирует около 87.5% изображений из тестового набора. По сравнению с первой моделью это значительное улучшение, и результат незначительно выше, чем у второй модели.

**Функция потерь (Loss)**
Значение функции потерь на тестовом наборе данных равно примерно 0.3670. Это значение немного выше, чем у второй модели, но всё ещё указывает на хорошее соответствие модели данным.

**Сравнение с предыдущими моделями**
Третья модель показывает улучшение по сравнению с первой моделью и небольшое преимущество по точности перед второй моделью. Добавление дополнительного полносвязного слоя позволило модели немного улучшить результаты.

Импортируем
необходимые библиотеки чтобы создать сверточную нейронную сеть.
"""

from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten
import numpy as np
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()
x_train = x_train[:,:,:,np.newaxis] / 255.0
x_test = x_test[:,:,:,np.newaxis] / 255.0
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

"""Опишем архитектуру сети 4:"""

model4 = Sequential()
model4.add(Conv2D(filters=64, kernel_size=2, padding='same',
activation='relu', input_shape=(28,28, 1)))
model4.add(MaxPooling2D(pool_size=2))
model4.add(Flatten())
model4.add(Dense(10, activation='softmax'))
model4.compile(loss='categorical_crossentropy', optimizer='adam',
metrics=['accuracy'])
model4.fit(x_train, y_train, epochs=10, validation_split=0.1)

test_acc = model4.evaluate(x_test, y_test)
print(test_acc)

"""Проанализируйте результат на проверочных и тестовых данных.

Результаты оценки четвёртой модели на тестовых данных включают два основных показателя:

Loss (функция потерь): 0.28379207849502563
Accuracy (точность): 0.8995 или 89.95%
Анализ результатов
Точность (Accuracy)
Точность модели на тестовом наборе данных составляет 89.95%. Это означает, что модель правильно классифицирует около 90% изображений из тестового набора. По сравнению с предыдущими моделями это значительное улучшение. Такой уровень точности является высоким для задачи классификации одежды с 10 классами.

**Функция потерь (Loss)**
Значение функции потерь на тестовом наборе данных равно примерно 0.284. Это значение ниже, чем у предыдущих моделей, что указывает на лучшее соответствие модели данным. Меньшее значение функции потерь означает, что предсказания модели более близки к истинным меткам классов.

**Сравнение с предыдущими моделями**
Четвёртая модель показывает значительное улучшение по сравнению с предыдущими моделями как по точности, так и по функции потерь. Использование свёрточной нейронной сети (CNN) позволило модели лучше обучаться на данных и улучшить результаты.

---


# **Проведите сравнение работы четырех архитектур. Какая из архитектур показывает лучший результат и почему? Как можно улучшить результаты каждой из архитектур?**

Сравнение работы четырёх архитектур


1.   Модель 1 Точность: 84.83% Функция потерь: 0.4316 Архитектура: простая полносвязная сеть с одним скрытым слоем из 10 нейронов.
2.   Модель 2 Точность: 87.15% Функция потерь: 0.3636 Архитектура: полносвязная сеть с одним скрытым слоем из 50 нейронов.
3.   Модель 3 Точность: 87.49% Функция потерь: 0.3670 Архитектура: полносвязная сеть с двумя скрытыми слоями по 50 нейронов каждый.
4.   Модель 4 Точность: 89.95% Функция потерь: 0.2838 Архитектура: свёрточная нейронная сеть (CNN) с одним свёрточным слоем и последующим полносвязным слоем.

***Анализ и выводы***
*Лучший результат показывает Модель 4*. Это обусловлено использованием свёрточной архитектуры, которая лучше подходит для обработки изображений и способна эффективно извлекать пространственные признаки.

***Возможные улучшения для каждой модели***


1.   Модель 1
Увеличение количества нейронов: добавление больше нейронов в единственный скрытый слой может улучшить способность модели к обучению.
Добавление скрытых слоёв: введение дополнительных полносвязных слоёв может помочь модели лучше обучаться на данных.
2.   Модель 2
Добавление скрытых слоёв: введение дополнительных полносвязных слоёв может улучшить результаты.
Регуляризация: применение методов регуляризации, таких как Dropout, может помочь предотвратить переобучение.
3.   Модель 3
Оптимизация гиперпараметров: настройка скорости обучения и других параметров оптимизатора может улучшить результаты.
Регуляризация: добавление Dropout или других методов регуляризации может помочь предотвратить переобучение.
4.   Модель 4
Увеличение количества свёрточных слоёв: введение дополнительных свёрточных слоёв может помочь модели лучше извлекать признаки из данных.
Использование более сложных архитектур: применение более сложных архитектур, таких как ResNet или VGG, может значительно улучшить результаты.

# Вариант 9


1.   Архитектура 2-4-2
2.   Скорость обучения 0.35
3.   Входной векторX={0.1 -0.1}
4.   Начальные значения весов взять произвольным образом из интервала [-0.3 0.3]
5.   Y= {0.5; -0.5}
"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout
from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

# --- Загрузка и предобработка данных ---
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()
num_classes = 10

# Нормализация и добавление канала (для CNN)
x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0
x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0

# One-hot кодирование меток
y_train = to_categorical(y_train, num_classes)
y_test = to_categorical(y_test, num_classes)

print('Размерность x_train:', x_train.shape)
print(x_train.shape[0], 'Размер train')
print(x_test.shape[0], 'Размер test')

# --- Гиперпараметры ---
batch_size = 128
epochs = 10
learning_rate = 0.35  # оптимальное значение для Adam

# --- Архитектура сверточной нейросети (CNN) ---
model = Sequential([
    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.25),

    Conv2D(64, kernel_size=(3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.25),

    Flatten(),
    Dense(128, activation='relu', kernel_initializer=RandomUniform(minval=-0.3, maxval=0.3)),
    Dropout(0.5),
    Dense(num_classes, activation='softmax',  kernel_initializer=RandomUniform(minval=-0.3, maxval=0.3))
])

# --- Компиляция модели ---
optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])

model.summary()

# --- Обучение ---
hist = model.fit(
    x_train, y_train,
    batch_size=batch_size,
    epochs=epochs,
    verbose=1,
    validation_split=0.1  # 10% от обучающих — на валидацию
)

print("✅ Модель успешно обучена")

# --- Сохранение модели ---
model.save('mnist_cnn_optimized.h5')
print("💾 Модель сохранена как mnist_cnn_optimized.h5")

# --- Оценка ---
score = model.evaluate(x_test, y_test, verbose=0)
print(f'📉 Потери на тесте: {score[0]:.4f}')
print(f'✅ Точность на тесте: {score[1]*100:.2f}%')

# --- Построение графика потерь ---
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(hist.history['loss'], label='Train Loss')
plt.plot(hist.history['val_loss'], label='Validation Loss')
plt.title('Потери по эпохам')
plt.xlabel('Эпоха')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

# --- Построение графика точности ---
plt.subplot(1, 2, 2)
plt.plot(hist.history['accuracy'], label='Train Accuracy')
plt.plot(hist.history['val_accuracy'], label='Validation Accuracy')
plt.title('Точность по эпохам')
plt.xlabel('Эпоха')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.initializers import RandomUniform
from tensorflow.keras.optimizers import SGD
import numpy as np

# --- Условия из варианта 9 ---
X = np.array([[0.1, -0.1]])  # входной вектор
Y = np.array([[0.5, -0.5]])  # эталонный выход
learning_rate = 0.35
epochs = 100

# --- Построение модели 2-4-2 ---
mlp_model = Sequential()
mlp_model.add(Dense(4, input_dim=2, activation='sigmoid',
                    kernel_initializer=RandomUniform(minval=-0.3, maxval=0.3)))
mlp_model.add(Dense(2, activation='sigmoid',
                    kernel_initializer=RandomUniform(minval=-0.3, maxval=0.3)))

# --- Компиляция и обучение ---
optimizer = SGD(learning_rate=learning_rate)
mlp_model.compile(optimizer=optimizer, loss='mse')

losses = []
accuracies = []

for epoch in range(epochs):
    mlp_model.fit(X, Y, epochs=1, verbose=0)
    pred = mlp_model.predict(X, verbose=0)
    loss = np.mean((Y - pred)**2)
    acc = 1 - np.mean(np.abs(Y - pred)) / np.mean(np.abs(Y))  # приближенная точность
    losses.append(loss)
    accuracies.append(acc)

print("\nИндивидуальный вариант №9 (MLP 2-4-2):")
print(f"Целевой выход: {Y}")
print(f"Выход сети после обучения: {pred.round(4)}")

# --- Визуализация потерь и точности ---
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(losses, marker='o', color='red')
plt.title("MLP 2-4-2: Ошибка по эпохам (MSE)")
plt.xlabel("Эпоха")
plt.ylabel("Ошибка")
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(accuracies, marker='o', color='green')
plt.title("MLP 2-4-2: Приближённая точность по эпохам")
plt.xlabel("Эпоха")
plt.ylabel("Точность")
plt.grid(True)

plt.tight_layout()
plt.show()